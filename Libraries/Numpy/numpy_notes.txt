Numpy is a python library

Numpy stands for numerical python.

Travis Oliphant developed numpy library in the year 2005.


1️⃣ Introduction to NumPy
Where it’s used in AI/ML & DS:

Loading datasets: NumPy is often the first step after loading a CSV in Pandas — you convert it into arrays for model training.

Image data: Images are stored as pixel arrays (NumPy arrays are perfect for this).

Mathematical simulations: Weather prediction, physics experiments, financial models.

Behind the scenes in ML libraries: TensorFlow, PyTorch use NumPy-like operations.

Problem faced by poeple when they only used python for data analysis

   1. It was very slow when working on large datasets like weather, stock market data
   2. People had to use loops to work on this datasets which was time consuming 
   3. They used lists but the lists are not memory efficient, not suitable for large data

Numpy was built to:
                  1. To handle large amount of numbers in little to no time (like millions of rows of data).
                  2. To overcome the slowness of lists and loops, and invented special arrays

Special arrays where super fast and memory efficient.They are advanced lists

Benefits of Numpy: 
1. Speed is 50 - 100x more than lists
2. Uses less memory
3. Easy math operations
4. Used in AI, DS and ML, stock market & finance, medical research, and image processing.

full method: parameters to know:
 
   np.full(shape, fill_value, dtype=None, order='C', *, like=None)
Parameter	           Description
shape	               Tuple indicating the shape of the array (e.g. (3, 3, 2))
(3, 3, 2)
 ↑  ↑  ↑
 |  |  └── 2 columns in each row
 |  └───── 3 rows in each block
 └──────── 3 blocks (or 3 matrices)
fill_value	           The value to fill the array with (e.g. 25)
dtype	                (Optional) Data type of the output array (e.g. int, float)
order	               (Optional) Row-major ('C') or column-major ('F') memory layout
like	               (Optional) Reference object to define the result's type and behavior

Array properties:

1. Numpy array carries shape, size and type of data, which we must know before performing any operations on it.

e.g. assume you are an data ware house manager, 
     there is lots of data of company products which you have to keep track of:
     1. product name
     2. Quantity of a product
     3. Price of the product
You must know product name, quantity i.e. shape() of the product, type of data of product 
     

shape method:  can be used to know the size of the array 
e.g. assume we have an excel table, shape tells us the dimensions of it

size method:  returns total numbers of elements in array
  e.g.  to know what is the size of a dataset 


MCQ:
Q1. NumPy arrays are faster than lists mainly because:
a) They store data in different types
b) They are written in C and store data in contiguous memory
c) They use loops internally
d) They can store any Python object

ans: b

MCQ:
Q2. What will be the output of:

import numpy as np
arr = np.arange(2, 10, 3)
print(arr)

a) [2 5 8]
b) [2 5 8 11]
c) [2 5 7]
d) [2 4 6]

ans: a

2️⃣ Creating NumPy Arrays (Deep Dive)
Theory:
Creating arrays is the first step in almost any numerical task. Arrays store data in a fast, compact way, and NumPy gives many shortcuts (zeros, ones, full, arange, linspace) to set up datasets without typing everything.

Where it’s used in AI/ML & DS:

Zeros & Ones: Initializing weights or bias arrays in ML models before training.

Full(): Setting all sensor readings to a default value before actual readings come in.

arange(): Generating index values for time series like stock prices or sensor data.

linspace(): Creating smooth points for plotting curves (e.g., sigmoid function).

Lists → Arrays: Converting raw dataset from CSV into NumPy arrays for faster math operations.

Example:

import numpy as np

# Image preprocessing: create a black image (all zeros)
black_img = np.zeros((100, 100, 3), dtype=np.uint8)

# Simulation: array of timestamps
timestamps = np.arange(0, 10, 0.5)

# ML weight initialization: all small values
weights = np.full((3, 3), 0.01)

MCQ:
Q2. np.linspace(0, 1, 5) generates:
a) [0, 1, 2, 3, 4]
b) [0. , 0.25, 0.5 , 0.75, 1.]
c) [0. , 0.2, 0.4, 0.6, 0.8]
d) Error

ans: b

3️⃣ Array Indexing & Slicing
Where it’s used in AI/ML & DS:

Feature selection: Picking specific columns (features) from your dataset.

Batch processing: Selecting rows in chunks during training.

Image cropping: Slicing a part of the image array for object detection tasks.

Time-series filtering: Extracting data for a specific time range.


MCQ:
Q3. What is the output of:

arr = np.array([[5, 6, 7], [8, 9, 10]])
print(arr[1, :2])

MCQ:
What will be the output of:
arr = np.arange(1, 7).reshape(2, 3)
print(arr[1, 1])

a) 2
b) 3
c) 5
d) 4

4️⃣ Understanding Random Module in NumPy.

Theory

NumPy’s random module lets you create random numbers or random samples quickly.
In AI/ML & Data Science, it’s used for:

Initializing model weights randomly before training

Splitting datasets into random train/test sets

Data augmentation (e.g., random noise for images)

Simulations (e.g., Monte Carlo simulations in finance or science)

5️⃣ Mathematical Operations in NumPy.

Theory (Layman’s Terms)

Mathematical operations in NumPy let you do fast, element-by-element math without writing loops.
If you have two arrays of the same size, NumPy can:

Add / subtract / multiply / divide them directly

Work with whole arrays instead of single numbers

Apply built-in math functions (sqrt, log, sin, etc.) instantly

AI/ML & DS Use Cases

Feature scaling: Dividing all values in a dataset by a constant to normalize

Loss calculation: Subtracting predicted values from actual values, squaring them, etc.

Image processing: Adding or subtracting brightness, multiplying for contrast

Signal processing: Applying trigonometric functions (sin, cos) to waveforms

Data transformation: Applying log() to skewed data for better ML performance



Q5. What will be the output?

arr = np.array([2, 4, 6])
print(np.sqrt(arr) + np.log(arr))

a) [1.69 2.39 2.78]
b) [2.34 3.09 3.48]
c) [2.34 3.08 3.48]
d) [2.10 3.38 4.24]

ans: d

6️⃣ NumPy Array Operations

Array operations in NumPy = built-in functions that work on the whole array at once.
Instead of looping, you can instantly get:

sum → total of all elements

mean → average value

min / max → smallest & largest value

std → standard deviation (spread of data)

var → variance (spread squared)

axis parameter → tells NumPy to work row-wise or column-wise

Array Operations – Detailed Theory (AI/ML & DS Use Cases)

1. sum / mean (average)

Why used: Quickly calculate total or average values without loops.

AI/ML examples:

Calculate average pixel brightness in an image dataset to check lighting conditions.

Compute average marks in a student performance dataset for analysis.

2. min / max (extremes)

Why used: Detect minimum and maximum values in a dataset.

AI/ML examples:

Find lowest and highest temperatures in climate data.

Detect extreme sensor readings for anomaly detection in IoT systems.

3. std / var (spread / variation)

Why used: Measure how spread out the data is from the mean.

AI/ML examples:

In finance, std shows stock market volatility.

In healthcare, track variation in patient vitals (heart rate, blood pressure).

4. axis=0 (column-wise)

Why used: Calculate statistics feature-by-feature (each column is a feature).

AI/ML examples:

Mean height, mean weight across all samples in a dataset.

Average pixel values per color channel (R, G, B) in image processing.

5. axis=1 (row-wise)

Why used: Calculate statistics sample-by-sample (each row is one observation).

AI/ML examples:

Total marks of each student in an exam dataset.

Average brightness of each image in a batch for quality control.


MCQ

Q6. What will be the output?

arr = np.array([[1, 2], [3, 4]])
print(np.sum(arr, axis=0))

a) [4 6]
b) [3 7]
c) [4 4]
d) [10]


7️⃣ Array Reshaping

Array reshaping = changing the shape (rows/columns) of data without changing the actual values.
You’re basically rearranging the same elements into a new grid layout.

NumPy’s main function:

array.reshape(new_shape)


New shape must have the same total number of elements as the original.

Use -1 to let NumPy auto-calculate that dimension.

AI/ML & DS Use Cases
1. Image Data – Flatten and Reshape

Flatten: Many ML algorithms (like logistic regression, fully connected neural nets) require 1D vectors as input. A 28×28 grayscale image (MNIST) must be reshaped into (784,).

Reshape back: After processing or predictions, you might need to reshape the data back into (28, 28) to display the image again.

Example: Handwritten digit recognition datasets often do this.

2. Batch Processing – (batch_size, features)

ML training often processes multiple samples at once (batch).

Example: If you have 10 samples, each with 5 features, your shape should be (10, 5).

Reshaping ensures each row = one sample, each column = one feature.

3. Time-Series – (samples,) → (samples, 1)

Some ML models (like scikit-learn regression) require 2D input, even for a single feature.

A 1D array like (100,) (100 days of stock prices) must be reshaped into (100, 1) so the algorithm sees it as 100 samples with 1 feature each.

4. 3D Data Handling – Images/Videos

Color images: Stored as (height, width, channels) → e.g., (64, 64, 3) for RGB images.

Videos: Stored as (frames, height, width) or (frames, height, width, channels) for colored video.

Reshaping helps when models expect different formats (e.g., CNNs vs. RNNs).


MCQ

Q7. What will this print?

arr = np.arange(8).reshape(2, -1)
print(arr.shape)


a) (2, 4)
b) (4, 2)
c) (8,)
d) Error

8️⃣ Random Number Generation

Random number generation in NumPy lets you create reproducible random data for experiments, simulations, and ML training.
It’s part of the numpy.random module, and you can:

Generate random integers

Generate random floats

Pick random elements from a set

Create numbers from statistical distributions (normal, uniform, etc.)

Set a seed so results are the same every time (important in experiments)

AI/ML & DS Use Cases

Reproducible Experiments

When training models, you often want the same random data split every time for consistent testing.

Achieved by setting a seed:

np.random.seed(42)


Synthetic Data Generation

For testing algorithms when real data isn’t available.

Example: Creating fake customer ages or income levels to check ML preprocessing.

Shuffling Datasets

Randomizing order before training prevents model bias.

Sampling from Distributions

Normal distribution: For simulating heights, weights, or measurement noise.

Uniform distribution: For evenly spread random values.



*** What is a Random Seed?

Think of random number generation like shuffling a deck of cards:

If you don’t fix the order, every shuffle will be different.

If you fix the shuffle pattern (e.g., always make the same moves), the cards will end up in the same order every time.

A seed is like fixing the shuffle pattern — it tells NumPy where to start in its random number sequence.

Why it matters in AI/ML

When you train a model, you might shuffle data, split train/test sets, or initialize weights randomly.

If you want to repeat the experiment and get the same result, you must set the seed.

Without a seed → results change every time you run the code.

With the same seed → same “random” values each time.

Effect of Setting a Seed in NumPy

If we set a seed using np.random.seed(value), NumPy will always give the same random values in the specified range (e.g., below 100) every time the code is run.

If we do not set a seed, NumPy will give different random values each time the code is run, even with the same range and size.


How to Decide a Seed Value in NumPy

The value you choose for the seed (e.g., 1, 7, 21, 42) does not affect randomness quality — it just picks the starting point in NumPy’s internal random sequence.

You can use any integer (usually a small, memorable one like 0, 1, 7, 21, 42) — it’s just for your reference.

The important thing is to reuse the same seed every time you want reproducible results.

📌 Rule of thumb in AI/ML:

Pick any number you like (common choice: 42 — popular from “The Hitchhiker’s Guide to the Galaxy” as “the answer to everything”).

Write it down in your project so you always use the same seed for experiments.
